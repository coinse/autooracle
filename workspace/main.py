import os 
import argparse
import subprocess 
import shlex
import json
from llm_api import query_chat_llm
from env import EvoD4jEnv
from evosuite import parse as parse_evosuite

prompt = """
You are an assistant for judging a test oracle. You will be presented with the body and error message of failing tests, 
and the test case generated by Evosuite for which you will have to verify whether the generated test case could reveals the buggy behavior of the target program or not.


This is the body of the failing test: 
```
{}
```

It failed with the following error messages:
```
{}
```

Please verify whether the program behavior captured in the generated test case is buggy or not.
```
{}
```

Respond with "Yes" when the generated test case captures the buggy behavior and "No" when it does not. If it is not related to the buggy behavior, respond with "Not related".
Don't need any commentary.

"""
def return_body_of_test(java_analyzer, path_to_failing_test_src, failing_test_body_dir, failing_test_class_name, failing_test_no):

    output = failing_test_class_name + '::' + failing_test_no
    output_json = failing_test_body_dir + output + '.json'
    
    subprocess.run(
        shlex.split("java -jar {} {} {}".format(java_analyzer, path_to_failing_test_src, output_json)),
                    universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    
    with open(output_json,"r") as f:
        data = json.load(f)
        for node in data["nodes"]:
            if node["type"] == "method" and node["signature"] == failing_test_class_name + '.' + failing_test_no + '()':
                begin_line =  node["begin_line"]
                end_line = node["end_line"]

    with open(path_to_failing_test_src,'r') as f :
        line = 0 
        source = ""
        for l in f :
            line += 1
            if line >= begin_line and line <= end_line:
                source += "Line "+ str(line) + ":\t" + l 

    with open(os.path.join(failing_test_body_dir, output), 'w') as f:
        f.write(source)

def test_path_to_class_name(test_path):
    return test_path[:-5].replace('/', '.')

def class_name_to_test_path(class_name):
    return class_name.replace('.', '/')+'.java'

def auto_oracle(project, version, ts_id):
    env = EvoD4jEnv(project, version, ts_id)
    """
    Collect EVO generated test's metadata
    """
    test_cases = {}
    for dp, dn, fn in os.walk(env.evosuite_test_src_dir):
        for f in fn:
            if f.endswith("ESTest.java"):
                relpath = os.path.relpath(os.path.join(dp, f), start = env.evosuite_test_src_dir)
                test_cases[relpath] = []
                coverage, test_content = parse_evosuite(os.path.join(dp, f))

                for test_no, test_src in test_content.items():
                    test_cases[relpath].append((test_no, test_src))
    """
    Load failing tests name
    """
    failing_tests =[]
    with open(env.failing_tests, 'r') as f:
        for l in f:
            failing_tests.append(l.strip())
    """
    Get failing tests body
    """
    # get source directory of tests : path_src_tests
    subprocess.run(
        shlex.split("defects4j export -p dir.src.tests -o {} -w {}".format(env.test_src_relpath, env.buggy_tmp_dir)),
        universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
     
    with open(env.test_src_relpath, "r") as f:
        test_src_relpath = f.read().strip()
    
    for ft in failing_tests:
        failing_test_class_name, failing_test_no = ft.split('::')
        path_to_failing_test_src = os.path.join(env.buggy_tmp_dir, test_src_relpath, class_name_to_test_path(failing_test_class_name))
        return_body_of_test(env.java_analyzer, path_to_failing_test_src, env.failing_test_body_dir, failing_test_class_name, failing_test_no)       
    """
    Excute failing tests
    """
    for ft in failing_tests :
         subprocess.run(
             shlex.split("defects4j test -w {} -t {}".format(env.buggy_tmp_dir, ft)),
             universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    """
    Parse failing tests exec results
    """
    fail_exec = {}
    print(os.path.join(env.buggy_tmp_dir,"failing_tests"))
    with open(os.path.join(env.buggy_tmp_dir,"failing_tests"),"r") as test_result:
        for l in test_result:
            if l.startswith("---"):
                failing_test = l[4:].strip()
                print(failing_test)
                fail_exec[failing_test] = ""
            elif "invoke0" in l:
                break
            else:
                fail_exec[failing_test] += l
   
    for relpath in test_cases: # to be queried
        for test_no, test_src in test_cases[relpath]:
            for failing_test,error_message in fail_exec.items():
                with open(os.path.join(env.failing_test_body_dir, failing_test),'r') as f:
                    failing_test_body = f.read().strip() 
                print(prompt.format(failing_test_body,error_message,test_src))
               
                query_chat_llm(prompt.format(failing_test_body,error_message,test_src))
                
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('project', type=str)
    parser.add_argument('version', type=str)
    parser.add_argument('--id', '-i', type=str, default='1')
    args = parser.parse_args()

    project = args.project
    version = args.version
    ts_id = args.id
    
    auto_oracle(project, version, ts_id)