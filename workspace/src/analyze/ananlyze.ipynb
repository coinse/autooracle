{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/coinse/.pyenv/versions/3.8.10/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/coinse/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/coinse/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/coinse/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/coinse/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/coinse/.pyenv/versions/3.8.10/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/home/coinse/.pyenv/versions/3.8.10/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "from IPython.display import display\n",
    "import pandas as pd \n",
    "import pickle\n",
    "import os \n",
    "from utils.env import EvoD4jEnv\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(project, version, ts_id, prompt_no, example_num, all_df, transformed=False):\n",
    "    env = EvoD4jEnv(project, version, ts_id=ts_id)\n",
    "    # Original \n",
    "    if transformed == False:\n",
    "        original_chat_reply_root_path = env.evosuite_chat_reply_dir.replace(\"/root/workspace\",\"/home/coinse/Workspace/hslee_workspace/autooracle/workspace\")\n",
    "        gt = \"correct\"\n",
    "        predict_str = \"predict_org\"\n",
    "    # Transformed\n",
    "    else:\n",
    "        original_chat_reply_root_path = env.evosuite_chat_reply_transform_dir.replace(\"/root/workspace\",\"/home/coinse/Workspace/hslee_workspace/autooracle/workspace\")\n",
    "        gt = \"incorrect\"\n",
    "        predict_str = \"predict_trs\"\n",
    "    \n",
    "    try_df_list = []\n",
    "    for try_no in range(1,4):\n",
    "        try_df = pd.DataFrame()\n",
    "        original_chat_reply_path = os.path.join(original_chat_reply_root_path, f\"prompt{prompt_no}/example{example_num}/try{try_no}\")\n",
    "        for file_name in os.listdir(original_chat_reply_path):\n",
    "            split_file_name = file_name.split('_')\n",
    "            test_class = split_file_name[0]\n",
    "            test_no = split_file_name[1]\n",
    "            oracle_type = split_file_name[2]\n",
    "            if oracle_type==\"assert\" or oracle_type==\"trycatch\":\n",
    "                with open(os.path.join(original_chat_reply_path, file_name)) as f:\n",
    "                    reply = f.read()\n",
    "                if re.search(\"undecidable\", reply):\n",
    "                    predict = \"undecidable\"\n",
    "                elif re.search(\"incorrect\", reply):\n",
    "                    predict = \"incorrect\"\n",
    "                elif re.search(\"correct\", reply):\n",
    "                    predict = \"correct\"\n",
    "                else: continue\n",
    "                df = pd.DataFrame({\"project\":[project], \"version\":[version], \"ts_id\":[ts_id], \"test_class\":[test_class], \"test_no\":[test_no], \"type\":[oracle_type], \"gt\":[gt], predict_str+f'_try{try_no}':[predict]})\n",
    "                try_df=pd.concat([try_df,df])\n",
    "                print(try_df)\n",
    "        try_df_list.append(try_df)\n",
    "    print(try_df_list)\n",
    "    \n",
    "    merge_try_dfs = pd.merge(left=try_df_list[0], right=try_df_list[1], on=[\"project\", \"version\", \"ts_id\", \"test_class\", \"test_no\", \"type\", \"gt\"])\n",
    "    merge_try_dfs = pd.merge(left=merge_try_dfs, right=try_df_list[2], on=[\"project\", \"version\", \"ts_id\", \"test_class\", \"test_no\", \"type\", \"gt\"])\n",
    "    \n",
    "    all_df = pd.concat([all_df, merge_try_dfs])\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def failing_test(project, version, ts_id, all_df, transformed=False):\n",
    "    env = EvoD4jEnv(project, version, ts_id)\n",
    "    failing_test_path = env.evosuite_test_dir.replace(\"/root/workspace\",\"/home/coinse/Workspace/hslee_workspace/autooracle/workspace\")\n",
    "    with open(os.path.join(failing_test_path, \"failing_tests_on_fixed\")) as f:\n",
    "        content = f.readlines()\n",
    "    fail_test_class =''\n",
    "    for l in content:\n",
    "        if l.startswith('---'):\n",
    "            pattern = r\"--- (.*?)::(.*?)$\"\n",
    "            match = re.search(pattern, l)\n",
    "            if match:\n",
    "                split_fail_test_class = match.group(1).split('.')\n",
    "                fail_test_class = '.'.join(split_fail_test_class[:-1])\n",
    "                fail_test_no = match.group(2).strip()\n",
    "                if fail_test_no[4]=='0' and len(fail_test_no)>5:\n",
    "                    fail_test_no = fail_test_no[:4]+fail_test_no[5]\n",
    "                # Original \n",
    "                if transformed == False:\n",
    "                    gt = \"incorrect\"\n",
    "                # Transformed\n",
    "                else:\n",
    "                    gt = \"correct\"\n",
    "                all_df.loc[(all_df[\"version\"]==version)&(all_df[\"test_class\"]==fail_test_class)&(all_df[\"test_no\"]==fail_test_no),\"gt\"] = gt\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(project, ts_id, prompt_no, example_num, versions, except_versions =[]):\n",
    "    org_df=pd.DataFrame()\n",
    "    trs_df=pd.DataFrame()\n",
    "\n",
    "    for version in versions:\n",
    "        if version in except_versions:\n",
    "            continue\n",
    "        org_df=get_data(project, version, ts_id, prompt_no, example_num, org_df, transformed=False)\n",
    "        org_df=failing_test(project, version, ts_id, org_df, transformed=False)\n",
    "        \n",
    "        trs_df=get_data(project, version, ts_id, prompt_no, example_num, trs_df, transformed=True)\n",
    "        trs_df=failing_test(project, version, ts_id, trs_df, transformed=True)\n",
    "\n",
    "    org_df=org_df.rename(columns={'gt':'gt_org'})\n",
    "    trs_df=trs_df.rename(columns={'gt':'gt_trs'})\n",
    "\n",
    "    all_df=pd.merge(left=org_df,right=trs_df,on=[\"project\", \"version\", \"ts_id\", \"test_class\", \"test_no\", \"type\"])\n",
    "    # all_df.drop(all_df[(all_df['predict_org_try1']=='undecidable') | (all_df['predict_org_try2']=='undecidable') |(all_df['predict_org_try3']=='undecidable') |(all_df['predict_trs_try1']=='undecidable') | (all_df['predict_trs_try2']=='undecidable') | (all_df['predict_trs_try3']=='undecidable')].index, inplace=True)\n",
    "    all_df[\"Predict\"] = 0\n",
    "    for j in range(1,4):\n",
    "        all_df.loc[all_df[\"predict_org_try{}\".format(j)] == \"correct\", \"Predict\"] += 1\n",
    "        all_df.loc[all_df[\"predict_org_try{}\".format(j)] == \"incorrect\", \"Predict\"] -= 1\n",
    "        all_df.loc[all_df[\"predict_org_try{}\".format(j)] == \"undecidable\", \"Predict\"] += 0\n",
    "        all_df.loc[all_df[\"predict_trs_try{}\".format(j)] == \"correct\", \"Predict\"] -= 1\n",
    "        all_df.loc[all_df[\"predict_trs_try{}\".format(j)]  == \"incorrect\", \"Predict\"] += 1\n",
    "        all_df.loc[all_df[\"predict_trs_try{}\".format(j)]  == \"undecidable\", \"Predict\"] += 0\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/coinse/Workspace/hslee_workspace/autooracle/workspace/result/Lang-1f_mutated/0/generated_test/newTS_600/chat_reply/prompt6/example2/try1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Lang_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLang\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnewTS_600\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m66\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexcept_versions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m26\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m38\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m43\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m53\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m55\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m63\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m df_list \u001b[38;5;241m=\u001b[39m [Lang_df]\n\u001b[1;32m      4\u001b[0m all_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(df_list, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m, in \u001b[0;36mget_dataframe\u001b[0;34m(project, ts_id, prompt_no, example_num, versions, except_versions)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;129;01min\u001b[39;00m except_versions:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m org_df\u001b[38;5;241m=\u001b[39m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morg_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m org_df\u001b[38;5;241m=\u001b[39mfailing_test(project, version, ts_id, org_df, transformed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m trs_df\u001b[38;5;241m=\u001b[39mget_data(project, version, ts_id, prompt_no, example_num, trs_df, transformed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(project, version, ts_id, prompt_no, example_num, all_df, transformed)\u001b[0m\n\u001b[1;32m     16\u001b[0m try_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     17\u001b[0m original_chat_reply_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(original_chat_reply_root_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/example\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/try\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtry_no\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_chat_reply_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     19\u001b[0m     split_file_name \u001b[38;5;241m=\u001b[39m file_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m     test_class \u001b[38;5;241m=\u001b[39m split_file_name[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/coinse/Workspace/hslee_workspace/autooracle/workspace/result/Lang-1f_mutated/0/generated_test/newTS_600/chat_reply/prompt6/example2/try1'"
     ]
    }
   ],
   "source": [
    "Lang_df = get_dataframe(\"Lang\", \"newTS_600\", 6, 2, list(range(1, 66)), except_versions =[ 2, 4, 19, 26, 28, 30, 38, 43, 48, 53, 55, 63])\n",
    "\n",
    "df_list = [Lang_df]\n",
    "all_df = pd.concat(df_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "passing_data = all_df.loc[all_df[\"gt_org\"]==\"correct\",:]\n",
    "failing_data = all_df.loc[all_df[\"gt_org\"]==\"incorrect\",:]\n",
    "display(passing_data.reset_index(drop=True))\n",
    "display(failing_data.reset_index(drop=True))\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original: correct / Transformed: incorrect\", fontdict = {'fontsize' : 20})\n",
    "a = sns.countplot(data=passing_data, x=\"Predict\", color='#4BC6CC')\n",
    "for p in a.patches:\n",
    "    height = p.get_height()\n",
    "    a.text(p.get_x() + p.get_width() / 2., height + 3, height, ha = 'center', size = 12)\n",
    "a.set_xlabel(\"Predict\", fontsize = 20)\n",
    "a.set_ylabel(\"number of test\", fontsize = 20)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Original: incorrect / Transformed: correct\", fontdict = {'fontsize' : 20})\n",
    "b= sns.countplot(data=failing_data, x=\"Predict\", color='#FF6E3E')\n",
    "for p in b.patches:\n",
    "    height = p.get_height()\n",
    "    b.text(p.get_x() + p.get_width() / 2., height + 0.1, height, ha = 'center', size = 12)\n",
    "b.set_xlabel(\"Predict\", fontsize = 20)\n",
    "b.set_ylabel(\"number of test\", fontsize = 20)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Original: correct / Transformed: incorrect\", passing_data[\"Predict\"].mean())\n",
    "print(\"Original: incorrect / Transformed: correct\", failing_data[\"Predict\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failing_data = all_df.loc[all_df[\"gt_org\"]==\"incorrect\",:]\n",
    "\n",
    "display(failing_data.sort_values(by='version', ascending = False))\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original: correct / Transformed: incorrect\", fontdict = {'fontsize' : 20})\n",
    "a = sns.countplot(data=passing_data, x=\"Predict\", color='#4BC6CC')\n",
    "for p in a.patches:\n",
    "    height = p.get_height()\n",
    "    a.text(p.get_x() + p.get_width() / 2., height + 3, height, ha = 'center', size = 12)\n",
    "a.set_xlabel(\"Predict\", fontsize = 20)\n",
    "a.set_ylabel(\"number of test\", fontsize = 20)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Original: incorrect / Transformed: correct\", fontdict = {'fontsize' : 20})\n",
    "b= sns.countplot(data=failing_data, x=\"Predict\", color='#FF6E3E')\n",
    "for p in b.patches:\n",
    "    height = p.get_height()\n",
    "    b.text(p.get_x() + p.get_width() / 2., height + 0.1, height, ha = 'center', size = 12)\n",
    "b.set_xlabel(\"Predict\", fontsize = 20)\n",
    "b.set_ylabel(\"number of test\", fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prompt_no = 4\n",
    "# example_num = 2\n",
    "\n",
    "# for _, row in failing_data.iterrows():\n",
    "#     pjoject = row['project']\n",
    "#     version = row['version']\n",
    "#     ts_id = row[\"ts_id\"]\n",
    "#     dir=row[\"test_class\"]\n",
    "#     test_no=row[\"test_no\"]\n",
    "#     oracle_type=row[\"type\"]\n",
    "\n",
    "#     individual_id=\"gpt4_incorrect\"\n",
    "\n",
    "#     for i in range(1,4):\n",
    "#         try_no=i \n",
    "\n",
    "#         script = f\"python query.py {pjoject} {version} -i {ts_id} -pn {prompt_no} -en {example_num} -t {try_no} -in -in_id {individual_id} -d {dir} -tn {test_no} -ot {oracle_type}\\n\"\n",
    "#         with open('./individual.sh','a') as f:\n",
    "#             f.write(script)\n",
    "\n",
    "#         script = f\"python query.py {pjoject} {version} -i {ts_id} -pn {prompt_no} -en {example_num} -t {try_no} -m -in -in_id {individual_id} -d {dir} -tn {test_no} -ot {oracle_type}\\n\"\n",
    "#         with open('./individual.sh','a') as f:\n",
    "#             f.write(script)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_df = pd.DataFrame()\n",
    "def get_data(individual_id, individual_df, transformed=False):\n",
    "    indiviual_root_path = os.path.join('/home/coinse/Workspace/hslee_workspace/autooracle/workspace/result/individual',individual_id)\n",
    "    # Original \n",
    "    if transformed == False:\n",
    "        chat_reply_root_path = os.path.join(indiviual_root_path, 'orginal')\n",
    "        gt = \"incorrect\"\n",
    "        predict_str = \"predict_org\"\n",
    "    # Transformed\n",
    "    else:\n",
    "        chat_reply_root_path = os.path.join(indiviual_root_path, 'mut')\n",
    "        gt = \"correct\"\n",
    "        predict_str = \"predict_trs\"\n",
    "\n",
    "    try_df_list = []    \n",
    "    for try_no in range(1,4):\n",
    "        try_df = pd.DataFrame()\n",
    "        chat_reply_path = os.path.join(chat_reply_root_path, f\"try{try_no}\")\n",
    "        for file_name in os.listdir(chat_reply_path):\n",
    "            split_file_name = file_name.split('_')\n",
    "            project = split_file_name[0]\n",
    "            version = split_file_name[1]\n",
    "            test_class = split_file_name[2]\n",
    "            test_no = split_file_name[3]\n",
    "            oracle_type = split_file_name[-1][:-4]\n",
    "            if oracle_type==\"assert\" or oracle_type==\"trycatch\":\n",
    "                with open(os.path.join(chat_reply_path, file_name)) as f:\n",
    "                    reply = f.read()\n",
    "                if re.search(\"incorrect\", reply):\n",
    "                    predict = \"incorrect\"\n",
    "                elif re.search(\"correct\", reply):\n",
    "                    predict = \"correct\"\n",
    "                df = pd.DataFrame({\"project\":[project], \"version\":[version], \"test_class\":[test_class], \"test_no\":[test_no], \"type\":[oracle_type], \"gt\":[gt], predict_str+f'_try{try_no}':[predict]})\n",
    "                try_df=pd.concat([try_df,df])\n",
    "        try_df_list.append(try_df)\n",
    "    \n",
    "    merge_try_dfs = pd.merge(left=try_df_list[0], right=try_df_list[1], on=[\"project\", \"version\", \"test_class\", \"test_no\", \"type\", \"gt\"])\n",
    "    merge_try_dfs = pd.merge(left=merge_try_dfs, right=try_df_list[2], on=[\"project\", \"version\", \"test_class\", \"test_no\", \"type\", \"gt\"])\n",
    "    \n",
    "    individual_df = pd.concat([individual_df, merge_try_dfs])\n",
    "    return individual_df\n",
    "\n",
    "org_df=pd.DataFrame()\n",
    "trs_df=pd.DataFrame()\n",
    "individual_id = \"gpt4_incorrect\"\n",
    "org_df=get_data(individual_id, individual_df, transformed=False)\n",
    "trs_df=get_data(individual_id, individual_df, transformed=True)\n",
    "\n",
    "org_df=org_df.rename(columns={'gt':'gt_org'})\n",
    "trs_df=trs_df.rename(columns={'gt':'gt_trs'})\n",
    "\n",
    "all_df=pd.merge(left=org_df,right=trs_df,on=[\"project\", \"version\", \"test_class\", \"test_no\", \"type\"])\n",
    "display(all_df)\n",
    "all_df[\"Predict\"] = 0\n",
    "for j in range(1,4):\n",
    "    all_df.loc[all_df[\"predict_org_try{}\".format(j)] == \"correct\", \"Predict\"] += 1\n",
    "    all_df.loc[all_df[\"predict_org_try{}\".format(j)] == \"incorrect\", \"Predict\"] -= 1\n",
    "    all_df.loc[all_df[\"predict_trs_try{}\".format(j)] == \"correct\", \"Predict\"] -= 1\n",
    "    all_df.loc[all_df[\"predict_trs_try{}\".format(j)]  == \"incorrect\", \"Predict\"] += 1\n",
    "#display(all_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
